{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be7001c8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f606001b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "from bs4 import BeautifulSoup\n",
    "import re \n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab9e7542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", (tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a778c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7c97879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0918e8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354084b6",
   "metadata": {},
   "source": [
    "## Load DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ef00f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>article</th>\n",
       "      <th>section_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b' we use the integral - field spectrograph sa...</td>\n",
       "      <td>b'according to the current galaxy formation pa...</td>\n",
       "      <td>b'introduction\\nsummary and conclusion\\nacknow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b\" we report on an effort to study the connect...</td>\n",
       "      <td>b\"the interaction between high power plasma je...</td>\n",
       "      <td>b'introduction\\ncomputational methods\\nmodel d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b' we consider the scenario of a magnetic fiel...</td>\n",
       "      <td>b'the interstellar medium ( ism ) exhibits str...</td>\n",
       "      <td>b'introduction\\nfront structure\\nphase transit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b' we present a model - independent analysis o...</td>\n",
       "      <td>b'accreting stellar - mass black holes in bina...</td>\n",
       "      <td>b'introduction\\nobservations and timing analys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b' we evaluate the feasibility of the implemen...</td>\n",
       "      <td>b'one of the most prominent applications in qu...</td>\n",
       "      <td>b'introduction\\nquantum repeater protocol opti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>b' clump clusters and chain galaxies in the hu...</td>\n",
       "      <td>b\"galaxies observed with the advanced camera f...</td>\n",
       "      <td>b'introduction\\ndata on udf bulges and clumps\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>b' recent advances in early detection and deta...</td>\n",
       "      <td>b\"within the fireball model for gamma - ray bu...</td>\n",
       "      <td>b'introduction\\nthe light curve and polarizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>b' the @xmath0 and @xmath1 meson production in...</td>\n",
       "      <td>b'the alice experiment @xcite scientific progr...</td>\n",
       "      <td>b'introduction\\nresults\\nconclusions\\nreferences'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>b' recently there have been experimental resul...</td>\n",
       "      <td>b'the wave nature of light which explains the ...</td>\n",
       "      <td>b'introduction\\nbabinet principle: poisson spo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>b' we show that it is decidable whether a tran...</td>\n",
       "      <td>b'in the area of model - checking , the search...</td>\n",
       "      <td>b' introduction\\n preliminaries\\na technical l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               abstract  \\\n",
       "0     b' we use the integral - field spectrograph sa...   \n",
       "1     b\" we report on an effort to study the connect...   \n",
       "2     b' we consider the scenario of a magnetic fiel...   \n",
       "3     b' we present a model - independent analysis o...   \n",
       "4     b' we evaluate the feasibility of the implemen...   \n",
       "...                                                 ...   \n",
       "9995  b' clump clusters and chain galaxies in the hu...   \n",
       "9996  b' recent advances in early detection and deta...   \n",
       "9997  b' the @xmath0 and @xmath1 meson production in...   \n",
       "9998  b' recently there have been experimental resul...   \n",
       "9999  b' we show that it is decidable whether a tran...   \n",
       "\n",
       "                                                article  \\\n",
       "0     b'according to the current galaxy formation pa...   \n",
       "1     b\"the interaction between high power plasma je...   \n",
       "2     b'the interstellar medium ( ism ) exhibits str...   \n",
       "3     b'accreting stellar - mass black holes in bina...   \n",
       "4     b'one of the most prominent applications in qu...   \n",
       "...                                                 ...   \n",
       "9995  b\"galaxies observed with the advanced camera f...   \n",
       "9996  b\"within the fireball model for gamma - ray bu...   \n",
       "9997  b'the alice experiment @xcite scientific progr...   \n",
       "9998  b'the wave nature of light which explains the ...   \n",
       "9999  b'in the area of model - checking , the search...   \n",
       "\n",
       "                                          section_names  \n",
       "0     b'introduction\\nsummary and conclusion\\nacknow...  \n",
       "1     b'introduction\\ncomputational methods\\nmodel d...  \n",
       "2     b'introduction\\nfront structure\\nphase transit...  \n",
       "3     b'introduction\\nobservations and timing analys...  \n",
       "4     b'introduction\\nquantum repeater protocol opti...  \n",
       "...                                                 ...  \n",
       "9995  b'introduction\\ndata on udf bulges and clumps\\...  \n",
       "9996  b'introduction\\nthe light curve and polarizati...  \n",
       "9997  b'introduction\\nresults\\nconclusions\\nreferences'  \n",
       "9998  b'introduction\\nbabinet principle: poisson spo...  \n",
       "9999  b' introduction\\n preliminaries\\na technical l...  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/sample_10k_data_for_visualization.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5203b3a",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9cf2a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36ed4f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "punc = string.punctuation\n",
    "\n",
    "df[\"article\"] = df[\"article\"].apply(eval)\n",
    "df[\"abstract\"] = df[\"abstract\"].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f46c20e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    tokens = [char for char in tokens if not char in punc]\n",
    "    \n",
    "    return (\" \".join(tokens)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed78e302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dark matter haloes e.g. happy dog cat,'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaner(\"dark matter haloes e.g. and but happy dog and cat, <h1>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32a1e24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1014/1153800922.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  newString = BeautifulSoup(newString, \"lxml\").text\n"
     ]
    }
   ],
   "source": [
    "df[\"abstract_clean\"] = df[\"abstract\"].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0802a281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1014/1153800922.py:3: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  newString = BeautifulSoup(newString, \"lxml\").text\n"
     ]
    }
   ],
   "source": [
    "df[\"article_clean\"] = df[\"article\"].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e05bf",
   "metadata": {},
   "source": [
    "## Define Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "851c6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")\n",
    "\n",
    "max_article_length = 2048\n",
    "max_abstract_length = 257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22b1a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    examples = examples[1]\n",
    "    model_inputs = tokenizer(examples[\"article_clean\"], max_length=max_article_length, \n",
    "                             padding= \"max_length\", truncation=True, return_attention_mask= False, return_token_type_ids= False,\n",
    "                             return_tensors= \"tf\")\n",
    "    \n",
    "    labels = tokenizer(text_target=examples[\"abstract_clean\"], max_length=max_abstract_length, \n",
    "                       padding= \"max_length\", truncation=True, return_tensors=\"tf\")\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173285fd",
   "metadata": {},
   "source": [
    "### Test tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85846a31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760f80f84d6046f0b3449b1bb871ead3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_articles = [preprocess_function(row) for row in tqdm(df.iterrows())]\n",
    "\n",
    "# Multiprocess this\n",
    "\n",
    "\n",
    "# pool = multiprocessing.Pool()\n",
    "# result = list(tqdm(pool.map(preprocess_function, df.loc[:200].iterrows()),total_length = df.shape[0]))\n",
    "# pool.close()\n",
    "# pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2482359b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,  8007, 10845, ..., 15864,   216,     2], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_articles[1][\"input_ids\"].numpy().reshape(max_article_length,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b422c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_articles[0][\"labels\"].shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290239c",
   "metadata": {},
   "source": [
    "### Make batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f49f3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "SHUFFLE_BUFFER_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7edb626",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_tensors = np.array([data['input_ids'].numpy().reshape(max_article_length,) for data in tokenized_articles])\n",
    "abstract_tensors = np.array([data['labels'].numpy().reshape(max_abstract_length,) for data in tokenized_articles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d702039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79800dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd5f869",
   "metadata": {},
   "source": [
    "## Save numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3dac4ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/articles_numpy_short.npy\",\"wb\") as f:\n",
    "    np.save(f, articles_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "751204bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/abstract_numpy_short.npy\",\"wb\") as f:\n",
    "    np.save(f, abstract_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09cd9f0",
   "metadata": {},
   "source": [
    "## Load numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e430982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/articles_numpy_short.npy\", \"rb\") as f:\n",
    "    articles_tensors = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "294df6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/abstract_numpy_short.npy\", \"rb\") as f:\n",
    "    abstract_tensors = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3aaf8ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = abstract_tensors[:,:-1]\n",
    "decoder_output = abstract_tensors[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99eac8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(((articles_tensors, decoder_input),decoder_output))\n",
    "dataset = dataset.shuffle(SHUFFLE_BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c26dfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ShuffleDataset element_spec=((TensorSpec(shape=(2048,), dtype=tf.int32, name=None), TensorSpec(shape=(256,), dtype=tf.int32, name=None)), TensorSpec(shape=(256,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b653689b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset.take(1000) \n",
    "train_dataset = dataset.skip(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c19dde2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f24d26bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LEDTokenizerFast(name_or_path='allenai/led-base-16384', vocab_size=50265, model_max_length=16384, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True)})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b1d6fd",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f78b3000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session() \n",
    "\n",
    "latent_dim= 32\n",
    "vocab_size = tokenizer.vocab_size - 30000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e849048",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7832067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(max_article_length,))\n",
    "input_embedding = tf.keras.layers.Embedding(vocab_size, latent_dim, trainable=True)(inputs) \n",
    "\n",
    "encoder_lstm1 = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "# encoder_output , state_h, state_c = encoder_lstm1(input_embedding) \n",
    "\n",
    "encoder_output1 , state_h1, state_c1 = encoder_lstm1(input_embedding) \n",
    "\n",
    "encoder_lstm2 = tf.keras.layers.LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "encoder_lstm3= tf.keras.layers.LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07946a29",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea6164a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = tf.keras.layers.Input(shape=(None,)) \n",
    "dec_emb_layer = tf.keras.layers.Embedding(vocab_size, latent_dim,trainable=True) \n",
    "dec_emb = dec_emb_layer(decoder_inputs) \n",
    "\n",
    "#LSTM using encoder_states as initial state\n",
    "decoder_lstm = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb, initial_state=[state_h, state_c]) \n",
    "\n",
    "decoder_dense = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_size, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c6f4e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2048)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 2048, 32)     648480      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 2048, 32),   8320        ['embedding[0][0]']              \n",
      "                                 (None, 32),                                                      \n",
      "                                 (None, 32)]                                                      \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 2048, 32),   8320        ['lstm[0][0]']                   \n",
      "                                 (None, 32),                                                      \n",
      "                                 (None, 32)]                                                      \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 32)     648480      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 2048, 32),   8320        ['lstm_1[0][0]']                 \n",
      "                                 (None, 32),                                                      \n",
      "                                 (None, 32)]                                                      \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 32),   8320        ['embedding_1[0][0]',            \n",
      "                                 (None, 32),                      'lstm_2[0][1]',                 \n",
      "                                 (None, 32)]                      'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 20265)  668745     ['lstm_3[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,998,985\n",
      "Trainable params: 1,998,985\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model([inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df3a2ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb7497d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[    0 38696   107 ...   645 40206     2]\n",
      " [    0   571  8645 ...  2301  6364     2]], shape=(2, 2048), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[    0 34996  1683  9624  1825   251  1186 23140  1743   634 16022  5638\n",
      "  44650    16   154  1421   787  1178 40051   288    12  9773 11324  9624\n",
      "   5447   403   787  1178 40051   134  5167  4359 41071  1122  1433  8069\n",
      "   3092   924   684  1575 34983 11221  4086 45615  5177 47696  3569  1177\n",
      "  26660  1634  3291  1246  2430  2167  2859  6787   976  4359 41071   787\n",
      "   1178 40051   176   959 45615  4359 41071  2198   430  5177 47696  3569\n",
      "     65  5181  4784  3094  5177 47696  3569 17369 21085  4634 16022  5638\n",
      "  44650 40206 44650 17369  8254   976  9164  4359 41071  4777  5181   882\n",
      "   2707 42694  1402   923  6731   882  2707   233 16022  5638 44650  4359\n",
      "   2430  2167  2859   739  3266  6731   882  2707  3335 31858 24414  3187\n",
      "   4359  3868 11493   787  1178 40051   176 41353   787  1178 40051   176\n",
      "  19220  3056  1663 16934  4292  4737  3891  5709   986  1200  2430  2167\n",
      "   2859 19220  3056  1663  4081  4044  1177 26660  1634  1494 17759     7\n",
      "   4122   139 14619   806 14223  8578  2583 10721  7367   449   257     7\n",
      "   4122   139 23902   290 38749  1236 20948     2     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1]\n",
      " [    0 28235   338 26545   731 25156  6287 44262 38970  8069   624  3229\n",
      "  17014  8194   457  8794 44834   338 26545   731  3905   476   488   787\n",
      "   1178 40051   288 33100  4683 42662 25286   526 40001  4747   801   787\n",
      "   1178 40051   134   220 14712  8523   787  1178 40051   176   787  1178\n",
      "  40051   246  1110 11781   614  7400  1427   787  1178 40051   306 25156\n",
      "   6287 44262 24248 23099 10597  5181   787  1178 40051   245   457  8794\n",
      "    787  1178 40051   401 40001   787  1178 40051   134   787  1178 40051\n",
      "    176  6235   787  1178 40051   406  1110   614  1007  4304  5425 32242\n",
      "   2228   775   614  1007 12562 29148 38970 18871  2862  1672 19855  1043\n",
      "    856  8362  2485 43681   787  1178 40051   306   239   615  9015 20129\n",
      "  27384  5181 20748 44834   338 26545   731 25156  6287 44262    80  5181\n",
      "  25549 44834   338 26545   731 25156  6287 44262   712  8617  5181  3488\n",
      "    614  5181  4304 20129  7280  5181  3488   239  3971 20129   528   157\n",
      "    684  7425   271  3432 15796  3538  1368  7067 23429  1571 16522   982\n",
      "    737 20748  5181  5685   787  1178 40051   306     2     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1]], shape=(2, 256), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[34996  1683  9624  1825   251  1186 23140  1743   634 16022  5638 44650\n",
      "     16   154  1421   787  1178 40051   288    12  9773 11324  9624  5447\n",
      "    403   787  1178 40051   134  5167  4359 41071  1122  1433  8069  3092\n",
      "    924   684  1575 34983 11221  4086 45615  5177 47696  3569  1177 26660\n",
      "   1634  3291  1246  2430  2167  2859  6787   976  4359 41071   787  1178\n",
      "  40051   176   959 45615  4359 41071  2198   430  5177 47696  3569    65\n",
      "   5181  4784  3094  5177 47696  3569 17369 21085  4634 16022  5638 44650\n",
      "  40206 44650 17369  8254   976  9164  4359 41071  4777  5181   882  2707\n",
      "  42694  1402   923  6731   882  2707   233 16022  5638 44650  4359  2430\n",
      "   2167  2859   739  3266  6731   882  2707  3335 31858 24414  3187  4359\n",
      "   3868 11493   787  1178 40051   176 41353   787  1178 40051   176 19220\n",
      "   3056  1663 16934  4292  4737  3891  5709   986  1200  2430  2167  2859\n",
      "  19220  3056  1663  4081  4044  1177 26660  1634  1494 17759     7  4122\n",
      "    139 14619   806 14223  8578  2583 10721  7367   449   257     7  4122\n",
      "    139 23902   290 38749  1236 20948     2     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1]\n",
      " [28235   338 26545   731 25156  6287 44262 38970  8069   624  3229 17014\n",
      "   8194   457  8794 44834   338 26545   731  3905   476   488   787  1178\n",
      "  40051   288 33100  4683 42662 25286   526 40001  4747   801   787  1178\n",
      "  40051   134   220 14712  8523   787  1178 40051   176   787  1178 40051\n",
      "    246  1110 11781   614  7400  1427   787  1178 40051   306 25156  6287\n",
      "  44262 24248 23099 10597  5181   787  1178 40051   245   457  8794   787\n",
      "   1178 40051   401 40001   787  1178 40051   134   787  1178 40051   176\n",
      "   6235   787  1178 40051   406  1110   614  1007  4304  5425 32242  2228\n",
      "    775   614  1007 12562 29148 38970 18871  2862  1672 19855  1043   856\n",
      "   8362  2485 43681   787  1178 40051   306   239   615  9015 20129 27384\n",
      "   5181 20748 44834   338 26545   731 25156  6287 44262    80  5181 25549\n",
      "  44834   338 26545   731 25156  6287 44262   712  8617  5181  3488   614\n",
      "   5181  4304 20129  7280  5181  3488   239  3971 20129   528   157   684\n",
      "   7425   271  3432 15796  3538  1368  7067 23429  1571 16522   982   737\n",
      "  20748  5181  5685   787  1178 40051   306     2     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1     1     1     1     1     1     1     1     1\n",
      "      1     1     1     1]], shape=(2, 256), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for (i,j), k in train_dataset.take(1):\n",
    "    print(i)\n",
    "    print(j)\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7debbac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds, val_ds = tf.keras.utils.split_dataset(\n",
    "#     train_dataset, left_size=0.9, right_size=0.1, shuffle=True, seed=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1799dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, j in train_ds.take(1):\n",
    "#     print(i.numpy().shape)\n",
    "#     print(j.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d876b204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(train_dataset, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, callbacks\u001b[38;5;241m=\u001b[39m[es])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=50, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7787eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train = [i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "baf285c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0 25421 34934 ...     1     1     1]\n",
      " [    0 42853   910 ...     1     1     1]\n",
      " [    0 25870   803 ...     1     1     1]\n",
      " ...\n",
      " [    0  7822 16546 ...     1     1     1]\n",
      " [    0 35248 21861 ...     1     1     1]\n",
      " [    0  5079  6533 ...     1     1     1]]\n",
      "[[    0 23375  2787 ...     1     1     1]\n",
      " [    0  3530    12 ...     1     1     1]\n",
      " [    0    29 43089 ...     1     1     1]\n",
      " ...\n",
      " [    0 41045 29515 ...     1     1     1]\n",
      " [    0 12406 24343 ...     1     1     1]\n",
      " [    0 38375 11747 ...  2397 15180     2]]\n"
     ]
    }
   ],
   "source": [
    "for i, j in train_ds.take(1).as_numpy_iterator():\n",
    "    print(i)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c9e6302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 8192), (32, 512))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.shape, j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "34edae2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['<s>',\n",
       "  'capacity',\n",
       "  'Ä characterization',\n",
       "  'Ä general',\n",
       "  'Ä wireless',\n",
       "  'Ä relay',\n",
       "  'Ä networks',\n",
       "  'Ä fundamental',\n",
       "  'Ä problem',\n",
       "  'Ä network',\n",
       "  'Ä information',\n",
       "  'Ä theory',\n",
       "  'Ä however',\n",
       "  'Ä capacity',\n",
       "  'Ä fully',\n",
       "  'Ä characterized',\n",
       "  'Ä even',\n",
       "  'Ä simplest',\n",
       "  'Ä network',\n",
       "  'Ä consisting',\n",
       "  'Ä single',\n",
       "  'Ä source',\n",
       "  'Ä single',\n",
       "  'Ä relay',\n",
       "  'Ä single',\n",
       "  'Ä destination',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä wireless',\n",
       "  'Ä environments',\n",
       "  'Ä transmit',\n",
       "  'Ä signal',\n",
       "  'Ä heard',\n",
       "  'Ä multiple',\n",
       "  'Ä nodes',\n",
       "  'Ä call',\n",
       "  'Ä broadcast',\n",
       "  'Ä nature',\n",
       "  'Ä wireless',\n",
       "  'Ä communication',\n",
       "  'Ä receiver',\n",
       "  'Ä receive',\n",
       "  'Ä super',\n",
       "  'position',\n",
       "  'Ä simultaneously',\n",
       "  'Ä transmitted',\n",
       "  'Ä signals',\n",
       "  'Ä multiple',\n",
       "  'Ä nodes',\n",
       "  'Ä call',\n",
       "  'Ä interference',\n",
       "  'Ä nature',\n",
       "  'Ä wireless',\n",
       "  'Ä communication',\n",
       "  'Ä furthermore',\n",
       "  'Ä wireless',\n",
       "  'Ä channels',\n",
       "  'Ä may',\n",
       "  'Ä time',\n",
       "  'Ä varying',\n",
       "  'Ä due',\n",
       "  'Ä fading',\n",
       "  'Ä noise',\n",
       "  'Ä receiver',\n",
       "  'Ä considering',\n",
       "  'Ä makes',\n",
       "  'Ä problem',\n",
       "  'Ä vary',\n",
       "  'Ä hard',\n",
       "  'Ä hence',\n",
       "  'Ä one',\n",
       "  'Ä promising',\n",
       "  'Ä approaches',\n",
       "  'Ä study',\n",
       "  'Ä simplified',\n",
       "  'Ä relay',\n",
       "  'Ä networks',\n",
       "  'Ä whose',\n",
       "  'Ä results',\n",
       "  'Ä provide',\n",
       "  'Ä insights',\n",
       "  'Ä towards',\n",
       "  'Ä exact',\n",
       "  'Ä approximate',\n",
       "  'Ä capacity',\n",
       "  'Ä characterization',\n",
       "  'Ä general',\n",
       "  'Ä wireless',\n",
       "  'Ä relay',\n",
       "  'Ä networks',\n",
       "  'Ä let',\n",
       "  'Ä us',\n",
       "  'Ä first',\n",
       "  'Ä look',\n",
       "  'Ä cases',\n",
       "  'Ä capacity',\n",
       "  'Ä known',\n",
       "  'Ä wire',\n",
       "  'line',\n",
       "  'Ä relay',\n",
       "  'Ä networks',\n",
       "  'Ä relay',\n",
       "  'Ä networks',\n",
       "  'Ä broadcast',\n",
       "  'Ä interference',\n",
       "  'Ä routing',\n",
       "  'Ä enough',\n",
       "  'Ä achieve',\n",
       "  'Ä unic',\n",
       "  'ast',\n",
       "  'Ä capacity',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä hand',\n",
       "  'Ä routing',\n",
       "  'Ä alone',\n",
       "  'Ä achieve',\n",
       "  'Ä multic',\n",
       "  'ast',\n",
       "  'Ä capacity',\n",
       "  'Ä network',\n",
       "  'Ä coding',\n",
       "  'Ä shown',\n",
       "  'Ä optimal',\n",
       "  'Ä case',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä deter',\n",
       "  'ministic',\n",
       "  'Ä relay',\n",
       "  'Ä networks',\n",
       "  'Ä interference',\n",
       "  'Ä unic',\n",
       "  'ast',\n",
       "  'Ä capacity',\n",
       "  'Ä characterized',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä extension',\n",
       "  'Ä multic',\n",
       "  'ast',\n",
       "  'Ä case',\n",
       "  'Ä recently',\n",
       "  'Ä studied',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä multic',\n",
       "  'ast',\n",
       "  'Ä capacity',\n",
       "  'Ä er',\n",
       "  'asure',\n",
       "  'Ä networks',\n",
       "  'Ä interference',\n",
       "  'Ä also',\n",
       "  'Ä characterized',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä broadcast',\n",
       "  'Ä unic',\n",
       "  'ast',\n",
       "  'Ä capacity',\n",
       "  'Ä er',\n",
       "  'asure',\n",
       "  'Ä networks',\n",
       "  'Ä characterized',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä dual',\n",
       "  'Ä network',\n",
       "  'Ä studied',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä mentioned',\n",
       "  'Ä networks',\n",
       "  'Ä unic',\n",
       "  'ast',\n",
       "  'Ä multic',\n",
       "  'ast',\n",
       "  'Ä capacity',\n",
       "  'Ä interpreted',\n",
       "  'Ä max',\n",
       "  'Ä flow',\n",
       "  'Ä min',\n",
       "  'Ä cut',\n",
       "  'Ä theorem',\n",
       "  '_.',\n",
       "  'Ä notice',\n",
       "  'Ä although',\n",
       "  'Ä orth',\n",
       "  'og',\n",
       "  'onal',\n",
       "  'Ä transmission',\n",
       "  'Ä reception',\n",
       "  'Ä possible',\n",
       "  'Ä practice',\n",
       "  'Ä using',\n",
       "  'Ä time',\n",
       "  'Ä frequency',\n",
       "  'Ä code',\n",
       "  'Ä division',\n",
       "  'Ä techniques',\n",
       "  'Ä sub',\n",
       "  'opt',\n",
       "  'imal',\n",
       "  'Ä general',\n",
       "  'Ä channels',\n",
       "  'Ä therefore',\n",
       "  'Ä simpl',\n",
       "  'ification',\n",
       "  'Ä wireless',\n",
       "  'Ä relay',\n",
       "  'Ä networks',\n",
       "  'Ä preserving',\n",
       "  'Ä broadcast',\n",
       "  'Ä interference',\n",
       "  'Ä n',\n",
       "  'atures',\n",
       "  'Ä cru',\n",
       "  'cially',\n",
       "  'Ä important',\n",
       "  'Ä capture',\n",
       "  'Ä essence',\n",
       "  'Ä wireless',\n",
       "  'Ä communication',\n",
       "  'Ä simplest',\n",
       "  'Ä model',\n",
       "  'Ä successfully',\n",
       "  'Ä reflects',\n",
       "  'Ä broadcast',\n",
       "  'Ä interference',\n",
       "  'Ä n',\n",
       "  'atures',\n",
       "  'Ä might',\n",
       "  'Ä linear',\n",
       "  'Ä finite',\n",
       "  'Ä field',\n",
       "  'Ä relay',\n",
       "  'Ä networks',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä node',\n",
       "  'Ä transm',\n",
       "  'its',\n",
       "  'Ä element',\n",
       "  'Ä finite',\n",
       "  'Ä field',\n",
       "  'Ä receives',\n",
       "  'Ä sum',\n",
       "  'Ä transmit',\n",
       "  'Ä signals',\n",
       "  'Ä finite',\n",
       "  'Ä field',\n",
       "  'Ä recently',\n",
       "  'Ä work',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä shown',\n",
       "  'Ä max',\n",
       "  'Ä flow',\n",
       "  'Ä min',\n",
       "  'Ä cut',\n",
       "  'Ä theorem',\n",
       "  'Ä also',\n",
       "  'Ä holds',\n",
       "  'Ä deter',\n",
       "  'ministic',\n",
       "  'Ä linear',\n",
       "  'Ä finite',\n",
       "  'Ä field',\n",
       "  'Ä relay',\n",
       "  'Ä networks',\n",
       "  'Ä capacity',\n",
       "  'Ä characterization',\n",
       "  'Ä linear',\n",
       "  'Ä finite',\n",
       "  'Ä field',\n",
       "  'Ä relay',\n",
       "  'Ä networks',\n",
       "  'Ä approximate',\n",
       "  'Ä capacity',\n",
       "  'Ä ga',\n",
       "  'ussian',\n",
       "  'Ä relay',\n",
       "  'Ä networks',\n",
       "  'Ä characterized',\n",
       "  'Ä within',\n",
       "  'Ä constant',\n",
       "  'Ä number',\n",
       "  'Ä bits',\n",
       "  'Ä using',\n",
       "  'Ä quant',\n",
       "  'ize',\n",
       "  'Ä random',\n",
       "  'Ä map',\n",
       "  'Ä forward',\n",
       "  'Ä authors',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä spite',\n",
       "  'Ä surging',\n",
       "  'Ä importance',\n",
       "  'Ä multi',\n",
       "  'Ä source',\n",
       "  'Ä relay',\n",
       "  'Ä networks',\n",
       "  'Ä capacity',\n",
       "  'Ä characterization',\n",
       "  'Ä much',\n",
       "  'Ä challenging',\n",
       "  'Ä exist',\n",
       "  'Ä multiple',\n",
       "  'Ä source',\n",
       "  'Ä destination',\n",
       "  'Ä pairs',\n",
       "  'Ä network',\n",
       "  'Ä even',\n",
       "  'Ä linear',\n",
       "  'Ä finite',\n",
       "  'Ä field',\n",
       "  'Ä relay',\n",
       "  'Ä networks',\n",
       "  'Ä extension',\n",
       "  'Ä results',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä multi',\n",
       "  'Ä source',\n",
       "  'Ä seem',\n",
       "  'Ä straightforward',\n",
       "  'Ä notice',\n",
       "  'Ä main',\n",
       "  'Ä difficulty',\n",
       "  'Ä arises',\n",
       "  'Ä fact',\n",
       "  'Ä transmission',\n",
       "  'Ä sessions',\n",
       "  'Ä acts',\n",
       "  'Ä inter',\n",
       "  'Ä user',\n",
       "  'Ä interference',\n",
       "  'Ä result',\n",
       "  'Ä cut',\n",
       "  'Ä set',\n",
       "  'Ä upper',\n",
       "  'Ä bound',\n",
       "  'Ä tight',\n",
       "  'Ä general',\n",
       "  'Ä due',\n",
       "  'Ä difficulties',\n",
       "  'Ä existing',\n",
       "  'Ä capacity',\n",
       "  'Ä approximate',\n",
       "  'Ä capacity',\n",
       "  'Ä results',\n",
       "  'Ä limited',\n",
       "  'Ä specific',\n",
       "  'Ä network',\n",
       "  'Ä top',\n",
       "  'ologies',\n",
       "  'Ä two',\n",
       "  'Ä user',\n",
       "  'Ä interference',\n",
       "  'Ä channel',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä many',\n",
       "  'Ä one',\n",
       "  'Ä interference',\n",
       "  'Ä channel',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä two',\n",
       "  'Ä way',\n",
       "  'Ä channel',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä two',\n",
       "  'Ä user',\n",
       "  'Ä two',\n",
       "  'Ä hop',\n",
       "  'Ä relay',\n",
       "  'Ä network',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä therefore',\n",
       "  'Ä one',\n",
       "  'Ä basic',\n",
       "  'Ä questions',\n",
       "  'Ä whether',\n",
       "  'Ä characterize',\n",
       "  'Ä capacity',\n",
       "  'Ä approximate',\n",
       "  'Ä capacity',\n",
       "  'Ä general',\n",
       "  'Ä network',\n",
       "  'Ä top',\n",
       "  'ologies',\n",
       "  'Ä classes',\n",
       "  'Ä relay',\n",
       "  'Ä networks',\n",
       "  'Ä paper',\n",
       "  'Ä study',\n",
       "  'Ä multi',\n",
       "  'Ä source',\n",
       "  'Ä linear',\n",
       "  'Ä finite',\n",
       "  'Ä field',\n",
       "  'Ä relay',\n",
       "  'Ä networks',\n",
       "  'Ä time',\n",
       "  'Ä varying',\n",
       "  'Ä channels',\n",
       "  'Ä capture',\n",
       "  'Ä three',\n",
       "  'Ä key',\n",
       "  'Ä characteristics',\n",
       "  'Ä wireless',\n",
       "  'Ä environment',\n",
       "  'Ä i',\n",
       "  '.',\n",
       "  'e',\n",
       "  '.',\n",
       "  'Ä broadcast',\n",
       "  'Ä interference',\n",
       "  'Ä fading',\n",
       "  'Ä note',\n",
       "  'Ä random',\n",
       "  'Ä coding',\n",
       "  'Ä strategy',\n",
       "  'Ä still',\n",
       "  'Ä optimal',\n",
       "  'Ä single',\n",
       "  'Ä source',\n",
       "  'Ä fading',\n",
       "  'Ä linear',\n",
       "  'Ä finite',\n",
       "  'Ä field',\n",
       "  'Ä relay',\n",
       "  'Ä networks',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä work',\n",
       "  'Ä anymore',\n",
       "  'Ä due',\n",
       "  'Ä inter',\n",
       "  'Ä user',\n",
       "  'Ä interference',\n",
       "  'Ä mentioned',\n",
       "  'Ä fundamental',\n",
       "  'Ä issue',\n",
       "  'Ä multi',\n",
       "  'Ä source',\n",
       "  'Ä networks',\n",
       "  'Ä manage',\n",
       "  'Ä inter',\n",
       "  'Ä user',\n",
       "  'Ä interference',\n",
       "  'Ä network',\n",
       "  'Ä observe',\n",
       "  'Ä fading',\n",
       "  'Ä play',\n",
       "  'Ä important',\n",
       "  'Ä role',\n",
       "  'Ä mitigating',\n",
       "  'Ä interference',\n",
       "  'Ä efficiently',\n",
       "  'Ä leads',\n",
       "  'Ä capacity',\n",
       "  'Ä characterization',\n",
       "  'Ä certain',\n",
       "  'Ä classes',\n",
       "  'Ä networks',\n",
       "  'Ä specifically',\n",
       "  'Ä single',\n",
       "  'Ä hop',\n",
       "  'Ä networks',\n",
       "  'Ä inter',\n",
       "  'Ä user',\n",
       "  'Ä interference',\n",
       "  'Ä removed',\n",
       "  'Ä completely',\n",
       "  'Ä destination',\n",
       "  'Ä using',\n",
       "  'Ä two',\n",
       "  'Ä particular',\n",
       "  'Ä channel',\n",
       "  'Ä instances',\n",
       "  'Ä jointly',\n",
       "  'Ä multi',\n",
       "  'Ä hop',\n",
       "  'Ä networks',\n",
       "  'Ä using',\n",
       "  'Ä series',\n",
       "  'Ä particular',\n",
       "  'Ä channel',\n",
       "  'Ä instances',\n",
       "  'Ä multiple',\n",
       "  'Ä hops',\n",
       "  'Ä destination',\n",
       "  'Ä also',\n",
       "  'Ä decode',\n",
       "  'Ä message',\n",
       "  'Ä without',\n",
       "  'Ä interference',\n",
       "  'Ä example',\n",
       "  'Ä consider',\n",
       "  'Ä three',\n",
       "  'Ä user',\n",
       "  'Ä linear',\n",
       "  'Ä binary',\n",
       "  'Ä field',\n",
       "  'Ä relay',\n",
       "  'Ä network',\n",
       "  'Ä fig',\n",
       "  'Ä fig',\n",
       "  'Ä interference',\n",
       "  '_',\n",
       "  'al',\n",
       "  'ignment',\n",
       "  '_',\n",
       "  'mit',\n",
       "  'igation',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '0',\n",
       "  'Ä denotes',\n",
       "  'Ä information',\n",
       "  'Ä bit',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '1',\n",
       "  '-',\n",
       "  'th',\n",
       "  'Ä source',\n",
       "  'Ä symbol',\n",
       "  'Ä node',\n",
       "  'Ä denotes',\n",
       "  'Ä transmit',\n",
       "  'Ä signal',\n",
       "  'Ä node',\n",
       "  'Ä single',\n",
       "  'Ä hop',\n",
       "  'Ä networks',\n",
       "  'Ä shown',\n",
       "  'Ä fig',\n",
       "  'Ä fig',\n",
       "  'Ä interference',\n",
       "  '_',\n",
       "  'al',\n",
       "  'ignment',\n",
       "  '_',\n",
       "  'mit',\n",
       "  'igation',\n",
       "  'Ä transmitting',\n",
       "  'Ä bit',\n",
       "  'Ä twice',\n",
       "  'Ä source',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '2',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '3',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '4',\n",
       "  'Ä destination',\n",
       "  'Ä cancel',\n",
       "  'Ä interference',\n",
       "  'Ä adding',\n",
       "  'Ä two',\n",
       "  'Ä received',\n",
       "  'Ä signals',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '2',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '3',\n",
       "  'Ä denote',\n",
       "  'Ä two',\n",
       "  'Ä channel',\n",
       "  'Ä instances',\n",
       "  'Ä first',\n",
       "  'Ä hop',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '5',\n",
       "  'Ä denotes',\n",
       "  'Ä identity',\n",
       "  'Ä matrix',\n",
       "  'Ä related',\n",
       "  'Ä works',\n",
       "  'Ä dealing',\n",
       "  'Ä insepar',\n",
       "  'ability',\n",
       "  'Ä parallel',\n",
       "  'Ä interference',\n",
       "  'Ä channels',\n",
       "  'Ä found',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä references',\n",
       "  'Ä therein',\n",
       "  'Ä idea',\n",
       "  'Ä opportun',\n",
       "  'istically',\n",
       "  'Ä pairing',\n",
       "  'Ä two',\n",
       "  'Ä channel',\n",
       "  'Ä instances',\n",
       "  'Ä i',\n",
       "  '.',\n",
       "  'e',\n",
       "  '.',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '4',\n",
       "  'Ä also',\n",
       "  'Ä appeared',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä considered',\n",
       "  'Ä different',\n",
       "  'Ä simpler',\n",
       "  'Ä way',\n",
       "  'Ä interference',\n",
       "  'Ä alignment',\n",
       "  'Ä @',\n",
       "  'xc',\n",
       "  'ite',\n",
       "  'Ä two',\n",
       "  'Ä hop',\n",
       "  'Ä networks',\n",
       "  'Ä shown',\n",
       "  'Ä fig',\n",
       "  'Ä fig',\n",
       "  'Ä interference',\n",
       "  '_',\n",
       "  'al',\n",
       "  'ignment',\n",
       "  '_',\n",
       "  'mit',\n",
       "  'igation',\n",
       "  'Ä b',\n",
       "  'Ä notice',\n",
       "  'Ä destination',\n",
       "  'Ä receive',\n",
       "  'Ä information',\n",
       "  'Ä bit',\n",
       "  'Ä without',\n",
       "  'Ä interference',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '6',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '7',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '8',\n",
       "  'Ä denote',\n",
       "  'Ä channel',\n",
       "  'Ä instances',\n",
       "  'Ä first',\n",
       "  'Ä second',\n",
       "  'Ä hop',\n",
       "  'Ä respectively',\n",
       "  'Ä similarly',\n",
       "  'Ä interference',\n",
       "  'Ä free',\n",
       "  'Ä communication',\n",
       "  'Ä possible',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '9',\n",
       "  '-',\n",
       "  'hop',\n",
       "  'Ä networks',\n",
       "  'Ä opportun',\n",
       "  'istically',\n",
       "  'Ä pairing',\n",
       "  'Ä series',\n",
       "  'Ä channel',\n",
       "  'Ä instances',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '7',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '10',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '11',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '12',\n",
       "  'Ä denotes',\n",
       "  'Ä channel',\n",
       "  'Ä instance',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '13',\n",
       "  '-',\n",
       "  'th',\n",
       "  'Ä hop',\n",
       "  'Ä based',\n",
       "  'Ä key',\n",
       "  'Ä observations',\n",
       "  'Ä propose',\n",
       "  'Ä block',\n",
       "  'Ä mark',\n",
       "  'ov',\n",
       "  'Ä encoding',\n",
       "  'Ä rel',\n",
       "  'aying',\n",
       "  'Ä schemes',\n",
       "  'Ä make',\n",
       "  'Ä opportun',\n",
       "  'istic',\n",
       "  'Ä pairing',\n",
       "  'Ä channel',\n",
       "  'Ä instances',\n",
       "  'Ä possible',\n",
       "  'Ä comparing',\n",
       "  'Ä achievable',\n",
       "  'Ä rate',\n",
       "  'Ä regions',\n",
       "  'Ä cut',\n",
       "  'Ä set',\n",
       "  'Ä upper',\n",
       "  'Ä bound',\n",
       "  'Ä characterize',\n",
       "  'Ä capacity',\n",
       "  'Ä region',\n",
       "  'Ä single',\n",
       "  'Ä hop',\n",
       "  'Ä networks',\n",
       "  'Ä sum',\n",
       "  'Ä capacity',\n",
       "  'Ä multi',\n",
       "  'Ä hop',\n",
       "  'Ä networks',\n",
       "  'Ä classes',\n",
       "  'Ä network',\n",
       "  'Ä top',\n",
       "  'ologies',\n",
       "  'Ä channel',\n",
       "  'Ä distributions',\n",
       "  'Ä paper',\n",
       "  'Ä organized',\n",
       "  'Ä follows',\n",
       "  'Ä section',\n",
       "  'Ä sec',\n",
       "  'Ä sys',\n",
       "  '_',\n",
       "  'model',\n",
       "  'Ä define',\n",
       "  'Ä network',\n",
       "  'Ä model',\n",
       "  'Ä state',\n",
       "  'Ä multi',\n",
       "  'Ä source',\n",
       "  'Ä relay',\n",
       "  'Ä problem',\n",
       "  'Ä not',\n",
       "  'ations',\n",
       "  'Ä used',\n",
       "  'Ä paper',\n",
       "  'Ä section',\n",
       "  'Ä sec',\n",
       "  'Ä con',\n",
       "  'verse',\n",
       "  'Ä derive',\n",
       "  'Ä general',\n",
       "  'Ä cut',\n",
       "  'Ä set',\n",
       "  'Ä upper',\n",
       "  'Ä bound',\n",
       "  'Ä used',\n",
       "  'Ä prove',\n",
       "  'Ä convers',\n",
       "  'es',\n",
       "  'Ä sections',\n",
       "  'Ä sec',\n",
       "  'Ä achie',\n",
       "  'v',\n",
       "  'ability',\n",
       "  '_',\n",
       "  'single',\n",
       "  'Ä sec',\n",
       "  'Ä achie',\n",
       "  'v',\n",
       "  'ability',\n",
       "  '_',\n",
       "  'multi',\n",
       "  'Ä section',\n",
       "  'Ä sec',\n",
       "  'Ä achie',\n",
       "  'v',\n",
       "  'ability',\n",
       "  '_',\n",
       "  'single',\n",
       "  'Ä block',\n",
       "  'Ä mark',\n",
       "  'ov',\n",
       "  'Ä encoding',\n",
       "  'Ä scheme',\n",
       "  'Ä proposed',\n",
       "  'Ä single',\n",
       "  'Ä hop',\n",
       "  'Ä networks',\n",
       "  'Ä achievable',\n",
       "  'Ä rate',\n",
       "  'Ä region',\n",
       "  'Ä derived',\n",
       "  'Ä character',\n",
       "  'izes',\n",
       "  'Ä capacity',\n",
       "  'Ä region',\n",
       "  'Ä certain',\n",
       "  'Ä classes',\n",
       "  'Ä networks',\n",
       "  'Ä section',\n",
       "  'Ä sec',\n",
       "  'Ä achie',\n",
       "  'v',\n",
       "  'ability',\n",
       "  '_',\n",
       "  'multi',\n",
       "  'Ä block',\n",
       "  'Ä mark',\n",
       "  'ov',\n",
       "  'Ä encoding',\n",
       "  'Ä rel',\n",
       "  'aying',\n",
       "  'Ä scheme',\n",
       "  'Ä proposed',\n",
       "  'Ä multi',\n",
       "  'Ä hop',\n",
       "  'Ä networks',\n",
       "  'Ä achievable',\n",
       "  'Ä rate',\n",
       "  'Ä region',\n",
       "  'Ä derived',\n",
       "  'Ä character',\n",
       "  'izes',\n",
       "  'Ä sum',\n",
       "  'Ä capacity',\n",
       "  'Ä certain',\n",
       "  'Ä classes',\n",
       "  'Ä networks',\n",
       "  'Ä conclude',\n",
       "  'Ä paper',\n",
       "  'Ä section',\n",
       "  'Ä sec',\n",
       "  'Ä conclusion',\n",
       "  'Ä refer',\n",
       "  'Ä proofs',\n",
       "  'Ä le',\n",
       "  'mm',\n",
       "  'as',\n",
       "  'Ä append',\n",
       "  'ices',\n",
       "  'Ä ii',\n",
       "  'Ä section',\n",
       "  'Ä first',\n",
       "  'Ä explain',\n",
       "  'Ä under',\n",
       "  'lining',\n",
       "  'Ä network',\n",
       "  'Ä model',\n",
       "  'Ä define',\n",
       "  'Ä achievable',\n",
       "  'Ä rate',\n",
       "  'Ä region',\n",
       "  'Ä not',\n",
       "  'ations',\n",
       "  'Ä used',\n",
       "  'Ä paper',\n",
       "  'Ä throughput',\n",
       "  'Ä paper',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '14',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '15',\n",
       "  'Ä denote',\n",
       "  'Ä matrix',\n",
       "  'Ä vector',\n",
       "  'Ä respectively',\n",
       "  'Ä symbol',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '16',\n",
       "  'Ä denotes',\n",
       "  'Ä set',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '17',\n",
       "  'Ä denotes',\n",
       "  'Ä cardinal',\n",
       "  'ity',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '16',\n",
       "  'Ä study',\n",
       "  'Ä layered',\n",
       "  'Ä network',\n",
       "  'Ä fig',\n",
       "  'Ä fig',\n",
       "  'Ä k',\n",
       "  'user',\n",
       "  '_',\n",
       "  'm',\n",
       "  'hop',\n",
       "  'Ä consists',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '18',\n",
       "  'Ä layers',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '19',\n",
       "  'Ä nodes',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '13',\n",
       "  '-',\n",
       "  'th',\n",
       "  'Ä layer',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '20',\n",
       "  'Ä let',\n",
       "  'Ä us',\n",
       "  'Ä denote',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '21',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '22',\n",
       "  'Ä @',\n",
       "  'x',\n",
       "  'math',\n",
       "  '23',\n",
       "  '-',\n",
       "  'th',\n",
       "  'Ä node',\n",
       "  'Ä refers',\n",
       "  ...],\n",
       " array([    0, 23375,  2787,  2148,   976,  3228,  1300,  6955, 12937,\n",
       "         4836,    65,  6451,   743,  1546,   335,  6680,   936,   959,\n",
       "         1341,  4087,  9235,  5453,  4504,  3222,  3018,  8149,  5152,\n",
       "         1533,  1300,  6381, 15029,  1546,  5650,   780,  1380,  4836,\n",
       "          311,  2148,   303, 13953,   892, 26956, 40001,   882,  1546,\n",
       "           86, 15958,  6237, 18293,  2308,  8149, 25189,   295, 15488,\n",
       "         6955,  4358, 14095, 25189,   310,   505,   774, 31904,  3222,\n",
       "         3018,  8149,  4296,   881, 13591,  3228, 13591,  4836, 15393,\n",
       "           92,  1803,  2458,  1417, 45278,  6258, 11918, 10419, 36861,\n",
       "         4238, 17496, 14958,  4238, 18746, 34882, 32234,  1162, 12818,\n",
       "          937,   847,   278,  2853,  8191,  2148,   976,   881, 13591,\n",
       "         4836,  6797,  2148,  3228, 13591,  4836, 17407,  4050,  4238,\n",
       "        26070,  4836,   299, 20643,  4050,   311,  2148,  3228,  1300,\n",
       "         4836, 19912, 19220,  3041,  5251,   847, 48337,     2,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1],\n",
       "       dtype=int32))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(i[0]), \n",
    "tokenizej[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "34aa2fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/sparse_categorical_crossentropy/clip_by_value/zeros_like' defined at (most recent call last):\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_58/2194197506.py\", line 1, in <module>\n      history = model.fit([i,j], j, epochs=2, batch_size=BATCH_SIZE, callbacks=[es])\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 526, in minimize\n      grads_and_vars = self.compute_gradients(loss, var_list, tape)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 259, in compute_gradients\n      grads = tape.gradient(loss, var_list)\nNode: 'gradient_tape/sparse_categorical_crossentropy/clip_by_value/zeros_like'\nCannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 32\n  }\n  dim {\n    size: 512\n  }\n  dim {\n    size: 50265\n  }\n}\n\n\t [[{{node gradient_tape/sparse_categorical_crossentropy/clip_by_value/zeros_like}}]] [Op:__inference_train_function_100578]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/sparse_categorical_crossentropy/clip_by_value/zeros_like' defined at (most recent call last):\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_58/2194197506.py\", line 1, in <module>\n      history = model.fit([i,j], j, epochs=2, batch_size=BATCH_SIZE, callbacks=[es])\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1650, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1027, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 526, in minimize\n      grads_and_vars = self.compute_gradients(loss, var_list, tape)\n    File \"/home/rootroot/miniconda3/envs/tf/lib/python3.9/site-packages/keras/optimizers/optimizer_experimental/optimizer.py\", line 259, in compute_gradients\n      grads = tape.gradient(loss, var_list)\nNode: 'gradient_tape/sparse_categorical_crossentropy/clip_by_value/zeros_like'\nCannot parse tensor from proto: dtype: DT_FLOAT\ntensor_shape {\n  dim {\n    size: 32\n  }\n  dim {\n    size: 512\n  }\n  dim {\n    size: 50265\n  }\n}\n\n\t [[{{node gradient_tape/sparse_categorical_crossentropy/clip_by_value/zeros_like}}]] [Op:__inference_train_function_100578]"
     ]
    }
   ],
   "source": [
    "history = model.fit([i,j], j, epochs=2, batch_size=BATCH_SIZE, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00604ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
